---
title: Addressing Bias in Active Learning with Depth Uncertainty Networks... or Not
abstract: Farquhar et al. [2021] show that correcting for active learning bias with
  underparameterised models leads to improved downstream performance. For overparameterised
  models such as NNs, however, correction leads either to decreased or unchanged performance.
  They suggest that this is due to an “overfitting bias” which offsets the active
  learning bias. We show that depth uncertainty networks operate in a low overfitting
  regime, much like underparameterised models. They should therefore see an increase
  in performance with bias correction. Surprisingly, they do not. We propose that
  this negative result, as well as the results Farquhar et al. [2021], can be explained
  via the lens of the bias-variance decomposition of generalisation error.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: murray22a
month: 0
tex_title: Addressing Bias in Active Learning with Depth Uncertainty Networks... or
  Not
firstpage: 59
lastpage: 63
page: 59-63
order: 59
cycles: false
bibtex_author: Murray, Chelsea and Allingham, James U. and Antor\'{a}n, Javier and
  Hern\'{a}ndez-Lobato, Jos\'{e} Miguel
author:
- given: Chelsea
  family: Murray
- given: James U.
  family: Allingham
- given: Javier
  family: Antorán
- given: José Miguel
  family: Hernández-Lobato
date: 2022-02-11
address:
container-title: Proceedings on "I (Still) Can't Believe It's Not Better!" at NeurIPS
  2021 Workshops
volume: '163'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 2
  - 11
pdf: https://proceedings.mlr.press/v163/murray22a/murray22a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v163/murray22a/murray22a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
